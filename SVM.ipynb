{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Apple       0.65      0.70      0.68        37\n",
      "      Orange       0.59      0.53      0.56        30\n",
      "\n",
      "    accuracy                           0.63        67\n",
      "   macro avg       0.62      0.62      0.62        67\n",
      "weighted avg       0.62      0.63      0.62        67\n",
      "\n",
      "\n",
      "üîÆ Predictions for images in 'predict' folder:\n",
      "üñºÔ∏è 'images.jpg' is predicted to be: üçä Orange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fayc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2687: UserWarning: labels size, 2, does not match size of target_names, 3\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ======= PARAMETERS =======\n",
    "image_size = (64, 64)  # Resize all images to 64x64\n",
    "data_dir = \"C:\\\\Users\\\\fayc3\\\\OneDrive\\\\Desktop\\\\Semestre 2\\\\Machine Learning\\\\3 Machine learning algorithm\\\\DATASETS\\\\Apple vs Orange\"\n",
    "predict_dir = \"C:\\\\Users\\\\fayc3\\\\OneDrive\\\\Desktop\\\\Semestre 2\\\\Machine Learning\\\\3 Machine learning algorithm\\\\DATASETS\\\\Apple vs Orange\\\\predict\"\n",
    "\n",
    "# ======= LOAD AND PREPROCESS DATA =======\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for label in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, label)\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, image_size)\n",
    "                X.append(img.flatten())  # Flatten the image into 1D array\n",
    "                y.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Skipped {img_path}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# ======= TRAIN / TEST SPLIT =======\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ======= TRAIN SVM MODEL =======\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ======= EVALUATE ON TEST SET =======\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"üìä Classification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=le.classes_,\n",
    "    labels=np.unique(y_test)\n",
    "))\n",
    "\n",
    "\n",
    "# ======= PREDICT NEW IMAGE =======\n",
    "print(\"\\nüîÆ Predictions for images in 'predict' folder:\")\n",
    "for filename in os.listdir(predict_dir):\n",
    "    file_path = os.path.join(predict_dir, filename)\n",
    "    img = cv2.imread(file_path)\n",
    "    if img is not None:\n",
    "        img_resized = cv2.resize(img, image_size).flatten().reshape(1, -1)\n",
    "        pred = model.predict(img_resized)\n",
    "        label = le.inverse_transform(pred)[0]\n",
    "        print(f\"üñºÔ∏è '{filename}' is predicted to be: üçé Apple\" if label.lower() == 'apple' else f\"üñºÔ∏è '{filename}' is predicted to be: üçä Orange\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Could not read image: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training SVM on text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\O'\n",
      "C:\\Users\\fayc3\\AppData\\Local\\Temp\\ipykernel_13756\\3888336692.py:12: SyntaxWarning: invalid escape sequence '\\O'\n",
      "  test_data = pd.read_csv(\"C:\\\\Users\\\\fayc3\\OneDrive\\\\Desktop\\\\Semestre 2\\\\Machine Learning\\\\3 Machine learning algorithm\\\\DATASETS\\\\aciimdb_test.csv\")\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fayc3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.90      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the IMDB dataset from CSV\n",
    "# Replace the file paths with the correct paths to your CSV files\n",
    "train_data = pd.read_csv(\"C:\\\\Users\\\\fayc3\\\\OneDrive\\\\Desktop\\\\Semestre 2\\\\Machine Learning\\\\3 Machine learning algorithm\\\\DATASETS\\\\IMDB Dataset.csv\")\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\fayc3\\OneDrive\\\\Desktop\\\\Semestre 2\\\\Machine Learning\\\\3 Machine learning algorithm\\\\DATASETS\\\\aciimdb_test.csv\")\n",
    "\n",
    "train_data = train_data.iloc[ :300, :]\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "# Separate features and labels\n",
    "X_train, y_train = train_data['review'], train_data['sentiment']\n",
    "X_test, y_test = test_data['review'], test_data['sentiment']\n",
    "\n",
    "# Convert sentiment labels to numerical values (e.g., positive -> 1, negative -> 0)\n",
    "y_train = y_train.map({'positive': 1, 'negative': 0})\n",
    "y_test = y_test.map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Create the pipeline\n",
    "text_clf = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', max_df=0.7),\n",
    "    LinearSVC()\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Text Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.43774479588073517\n",
      "R^2 Score: 0.9997502253696101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('C:\\\\Users\\\\fayc3\\\\OneDrive\\\\Desktop\\\\Semestre 2\\\\Machine Learning\\\\3 Machine learning algorithm\\\\DATASETS\\\\all_stocks_5yr.csv')\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "# Drop unnecessary columns like 'date' and 'Name', and drop rows with missing values\n",
    "data_dropped = data.drop(['date', 'Name', 'volume'], axis=1)\n",
    "data_dropped = data_dropped.dropna()\n",
    "\n",
    "# Select a subset of rows and columns for training (adjust as necessary)\n",
    "data_dropped = data_dropped.iloc[:3000, :]  # First 3000 rows\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_dropped.drop('open', axis=1)  # Features\n",
    "y = data_dropped['open']  # Target variable\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train the SVR model\n",
    "svr_model = SVR(kernel='linear', C=1.0)  # You can change the kernel to 'rbf', 'poly', etc.\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
